import streamlit as st
import feedparser
import time
from datetime import datetime, timedelta
import json
import os

# ================= é é¢è¨­å®š =================
st.set_page_config(
    page_title="ThaiNews.Ai | æˆ°æƒ…å®¤", 
    page_icon="ğŸ‡¹ğŸ‡­", 
    layout="wide"
)

# ================= CSS ç¾åŒ– (æ¥µç°¡å¡ç‰‡é¢¨) =================
st.markdown("""
<style>
    .big-font { font-size: 32px !important; font-weight: 800; color: #1a1a1a; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; font-weight: bold; }
    .stCode { border: 1px solid #d93025; }
    
    /* æ–°èå¡ç‰‡æ¨£å¼ */
    .news-card {
        background-color: white;
        padding: 15px;
        border-radius: 8px;
        border: 1px solid #e0e0e0;
        margin-bottom: 10px;
        border-left: 5px solid #d93025; /* æ³°åœ‹ç´… */
        transition: transform 0.2s;
    }
    .news-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .news-title {
        font-size: 18px;
        font-weight: 700;
        color: #1a1a1a;
        text-decoration: none;
        display: block;
        margin-bottom: 5px;
    }
    .news-meta {
        font-size: 14px;
        color: #666;
    }
    .news-tag {
        background-color: #f0f0f0;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 12px;
        margin-left: 10px;
        color: #555;
    }
</style>
""", unsafe_allow_html=True)

# ================= çˆ¬èŸ²æ ¸å¿ƒé‚è¼¯ =================

def get_rss_sources(days, custom_keyword=None, category_mode=None):
    sources = []
    
    # === æ¨¡å¼ Aï¼šæ·±åº¦é‘½ç ” (åªæœè‡ªè¨‚) ===
    if custom_keyword and custom_keyword.strip():
        clean_keyword = custom_keyword.strip().replace(" ", "+")
        sources.append({
            "name": f"ğŸ” æ·±åº¦è¿½è¹¤: {custom_keyword} (EN)",
            "url": f"https://news.google.com/rss/search?q={clean_keyword}+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"
        })
        sources.append({
            "name": f"ğŸ” æ·±åº¦è¿½è¹¤: {custom_keyword} (ä¸­æ–‡)",
            "url": f"https://news.google.com/rss/search?q={clean_keyword}+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
        })
        return sources

    # === æ¨¡å¼ Bï¼šå»£åº¦æƒæ (å€åˆ†é¡åˆ¥) ===
    
    # å®šç¾©å„é¡åˆ¥çš„ URL
    
    # 1. General & Relations
    src_general_en = {
        "name": "ğŸ‡¹ğŸ‡­ 1. æ³°åœ‹æ•´é«”é‡è¦æ–°è (EN)", 
        "url": f"https://news.google.com/rss/search?q=Thailand+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"
    }
    src_general_cn = {
        "name": "ğŸ‡¹ğŸ‡­ 1. æ³°åœ‹æ•´é«”é‡è¦æ–°è (ä¸­æ–‡)", 
        "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    }
    src_relations_en = {
        "name": "ğŸ‡¹ğŸ‡¼ 2. å°æ³°é—œä¿‚ (EN)", 
        "url": f"https://news.google.com/rss/search?q=Thailand+Taiwan+OR+%22Taiwanese+investment%22+OR+%22Taiwan+companies%22+OR+%22Trade+Relations%22+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"
    }
    src_relations_cn = {
        "name": "ğŸ‡¹ğŸ‡¼ 2. å°æ³°é—œä¿‚ (ä¸­æ–‡)", 
        "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+å°ç£+OR+%22å°å•†%22+OR+%22æŠ•è³‡%22+OR+%22ç¶“è²¿%22+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    }

    # 2. PCB & Electronics
    src_pcb_en = {
        "name": "ğŸ”Œ 3. PCB èˆ‡é›»å­è£½é€  (EN)", 
        "url": f"https://news.google.com/rss/search?q=Thailand+PCB+OR+%22Printed+Circuit+Board%22+OR+%22Electronics+Manufacturing%22+OR+%22Server+Production%22+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"
    }
    src_pcb_cn = {
        "name": "ğŸ”Œ 3. PCB èˆ‡é›»å­è£½é€  (ä¸­æ–‡)", 
        "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+PCB+OR+%22å°åˆ·é›»è·¯æ¿%22+OR+%22é›»å­è£½é€ %22+OR+%22ä¼ºæœå™¨%22+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    }

    # 3. VIP Companies
    vip_companies_en = [
        '"Delta Electronics"', '"Zhen Ding"', '"Unimicron"', '"Compeq"', 
        '"Gold Circuit Electronics"', '"Dynamic Holding"', '"Tripod Technology"', 
        '"Unitech"', '"Foxconn"', '"Inventec"'
    ]
    vip_query_en = "+OR+".join([c.replace(" ", "+") for c in vip_companies_en])
    vip_companies_cn = [
        '"å°é”é›»"', '"è‡»é¼"', '"æ¬£èˆˆ"', '"è¯é€š"', 
        '"é‡‘åƒé›»"', '"å®šç©"', '"å¥é¼"', 
        '"ç‡¿è¯"', '"é´»æµ·"', '"è‹±æ¥­é”"'
    ]
    vip_query_cn = "+OR+".join([c.replace(" ", "+") for c in vip_companies_cn])

    src_vip_en = {
        "name": "ğŸ¢ 4. é‡é»å°å•†å‹•æ…‹è¿½è¹¤ (EN)",
        "url": f"https://news.google.com/rss/search?q=Thailand+PCB+OR+{vip_query_en}+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"
    }
    src_vip_cn = {
        "name": "ğŸ¢ 4. é‡é»å°å•†å‹•æ…‹è¿½è¹¤ (ä¸­æ–‡)",
        "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+OR+{vip_query_cn}+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    }

    # === æ ¹æ“š category_mode å›å‚³å°æ‡‰æ¸…å–® ===
    if category_mode == 'general':
        return [src_general_en, src_general_cn, src_relations_en, src_relations_cn]
    
    elif category_mode == 'pcb':
        return [src_pcb_en, src_pcb_cn]
        
    elif category_mode == 'vip':
        return [src_vip_en, src_vip_cn]
    
    else:
        # Fallback (å…¨éƒ¨å›å‚³ï¼Œå¦‚æœä¸å°å¿ƒæ²’æŒ‡å®šæ¨¡å¼)
        return [
            src_general_en, src_general_cn, 
            src_relations_en, src_relations_cn,
            src_pcb_en, src_pcb_cn,
            src_vip_en, src_vip_cn
        ]

def generate_chatgpt_prompt(days_label, days_int, custom_keyword, category_mode=None):
    status_text = st.empty() 
    progress_bar = st.progress(0)
    
    sources = get_rss_sources(days_int, custom_keyword, category_mode)
    
    news_items_for_json = []

    # === ç”Ÿæˆ Prompt (é‡å°ä¸åŒæŒ‰éˆ•å®¢è£½åŒ–è§’è‰²èˆ‡æŒ‡ä»¤) ===
    if custom_keyword and custom_keyword.strip():
        # è‡ªè¨‚æœå°‹æ¨¡å¼
        role = "ç”¢æ¥­åˆ†æå¸«"
        focus = f"é‡å°é—œéµå­—ã€{custom_keyword}ã€‘"
        instruction = "è«‹æ’°å¯«ä¸€ä»½ã€Œæ·±åº¦ä¸»é¡Œåˆ†æå ±å‘Šã€ï¼ŒåŒ…å«ï¼šé‡é»æ‘˜è¦ã€å¸‚å ´å½±éŸ¿ã€æ½›åœ¨æ©Ÿæœƒèˆ‡é¢¨éšªã€‚"
    
    elif category_mode == 'general':
        # 1. æ³°åœ‹æ•´é«” + å°æ³°é—œä¿‚
        role = "æ³°åœ‹æ”¿ç¶“è§€å¯Ÿå®¶"
        focus = f"ã€{days_label} æ³°åœ‹æ”¿ç¶“å±€å‹¢èˆ‡å°æ³°é—œä¿‚ã€‘"
        instruction = """
è«‹é‡é»åˆ†æï¼š
1. æ³°åœ‹é‡å¤§æ”¿æ²»èˆ‡ç¶“æ¿Ÿæ”¿ç­–è®Šå‹•ã€‚
2. å°æ³°é›™é‚Šé—œä¿‚ã€ç¶“è²¿äº’å‹•æˆ–æŠ•è³‡æ–°è¨Šã€‚
3. ç¤¾æœƒå®‰å…¨æˆ–æ—…éŠç›¸é—œçš„é‡è¦å½±éŸ¿ã€‚
"""
    elif category_mode == 'pcb':
        # 2. PCB é›»å­è£½é€ 
        role = "é›»å­ä¾›æ‡‰éˆå°ˆå®¶"
        focus = f"ã€{days_label} æ³°åœ‹ PCB èˆ‡é›»å­è£½é€ æ¥­æƒ…å ±ã€‘"
        instruction = """
è«‹é‡é»åˆ†æï¼š
1. PCB ç”¢æ¥­åœ¨æ³°åœ‹çš„æ“´å» ã€æŠ•è³‡å‹•æ…‹ã€‚
2. ä¸Šä¸‹æ¸¸ä¾›æ‡‰éˆçš„èšè½è®ŠåŒ–ã€‚
3. ä¼ºæœå™¨èˆ‡æ¶ˆè²»é›»å­çš„ç”Ÿç”¢è¶¨å‹¢ã€‚
"""
    elif category_mode == 'vip':
        # 3. é‡é»å°å•†
        role = "ç§‘æŠ€ç”¢æ¥­è­‰åˆ¸åˆ†æå¸«"
        focus = f"ã€{days_label} é‡é»å°å•†èˆ‡ç§‘æŠ€å¤§å» å‹•æ…‹ã€‘"
        instruction = """
ç›®æ¨™å…¬å¸ï¼šå°é”é›»ã€é´»æµ·ã€è‹±æ¥­é”ã€è‡»é¼ã€æ¬£èˆˆã€è¯é€šã€é‡‘åƒé›»ã€å¥é¼ã€å®šç©ã€ç‡¿è¯ã€‚
è«‹é‡é»åˆ†æï¼š
1. å€‹åˆ¥å…¬å¸åœ¨æ³°åœ‹çš„æ–°èã€æ“´ç”¢æˆ–ç‡Ÿé‹ç‹€æ³ã€‚
2. ç«¶çˆ­å°æ‰‹æˆ–åˆä½œå¤¥ä¼´çš„ç›¸é—œæ¶ˆæ¯ã€‚
3. è‚¡åƒ¹æˆ–ç‡Ÿæ”¶ç›¸é—œçš„ç•¶åœ°å ±å°ï¼ˆè‹¥æœ‰ï¼‰ã€‚
"""
    else:
        # Fallback
        role = "æ±å—äºç”¢ç¶“åˆ†æå¸«"
        focus = "æ³°åœ‹ç”¢æ¥­æ–°è"
        instruction = "è«‹åˆ†æï¼š1.æ³°åœ‹æ•´é«” 2.é›»å­è£½é€  3.å°æ³°é—œä¿‚ 4.å°å•†å‹•æ…‹"

    instruction_prompt = f"""
è«‹æ‰®æ¼”ä¸€ä½è³‡æ·±çš„ã€Œ{role}ã€ã€‚
ä»¥ä¸‹æ˜¯{focus}çš„æ–°èè³‡æ–™åº«ï¼ˆä¸­è‹±é›™èªï¼‰ã€‚
{instruction}
"""

    output_text = f"""
{instruction_prompt}

è«‹ç”¨**ç¹é«”ä¸­æ–‡**ï¼Œä¸¦ä»¥ **Markdown** æ¢åˆ—å¼è¼¸å‡ºï¼Œé¢¨æ ¼éœ€å°ˆæ¥­ä¸”æ˜“è®€ã€‚

========= ä»¥ä¸‹æ˜¯æ–°èè³‡æ–™åº« ({datetime.now().strftime('%Y-%m-%d')}) =========
"""
    
    seen_titles = set()
    total_steps = len(sources)
    
    for i, source in enumerate(sources):
        status_text.text(f"ğŸ“¡ æ­£åœ¨æƒæ: {source['name']} ...")
        
        try:
            feed = feedparser.parse(source['url'])
            
            if len(feed.entries) > 0:
                output_text += f"\n## ã€{source['name']}ã€‘\n"
                
                # å› ç‚ºæ‹†æˆä¸åŒæŒ‰éˆ•ï¼Œæ¯å€‹é¡åˆ¥çš„æ–°èé‡å¯ä»¥æ”¾å¯¬ï¼Œè®“ User ä¸æ€•æ¼æ–°è
                limit = 25 
                
                for entry in feed.entries[:limit]: 
                    if entry.title in seen_titles: continue
                    seen_titles.add(entry.title)
                    
                    source_name = entry.source.title if 'source' in entry else "Google News"
                    pub_date = entry.published if 'published' in entry else ""
                    
                    # 1. åŠ å…¥ Prompt
                    output_text += f"- [{pub_date}] [{source_name}] {entry.title}\n  é€£çµ: {entry.link}\n"
                    
                    # 2. åŠ å…¥ JSON å­˜æª”
                    news_items_for_json.append({
                        "title": entry.title,
                        "link": entry.link,
                        "date": pub_date,
                        "source": source_name,
                        "category": source['name']
                    })
            else:
                output_text += f"\n## ã€{source['name']}ã€‘\n(ç„¡ç›¸é—œæ–°è)\n"

        except Exception as e:
            st.error(f"æŠ“å–éŒ¯èª¤: {e}")
        
        progress_bar.progress((i + 1) / total_steps)
        time.sleep(0.5)

    output_text += "\n========= è³‡æ–™çµæŸ ========="
    
    # === å„²å­˜è‡³ JSON ===
    # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ 'a' (append) æ¨¡å¼å¯èƒ½æ›´é›£ç®¡ç†ï¼Œæˆ‘å€‘ç¶­æŒ 'w' è¦†å¯«ï¼Œä½† User æ‡‰çŸ¥æ›‰
    # è‹¥è¦ä¿ç•™æ‰€æœ‰é¡åˆ¥ï¼Œå¯èƒ½éœ€è¦å…ˆè®€å–å†åˆä½µï¼Œä½†ç‚ºäº† Prompt ç”Ÿæˆçš„ä¸€è‡´æ€§ï¼Œ
    # é€™è£¡çš„é‚è¼¯æ˜¯ã€Œæœ€å¾Œä¸€æ¬¡æœå°‹çš„å…§å®¹ã€æœƒé¡¯ç¤ºåœ¨ Tab 2ã€‚
    # ç‚ºäº†è‰¯å¥½çš„ UXï¼Œæˆ‘å€‘åœ¨ Tab 2 å¯èƒ½éœ€è¦èªªã€Œé¡¯ç¤ºæœ€è¿‘ä¸€æ¬¡æœå°‹çµæœã€ã€‚
    
    try:
        with open('news_data.json', 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "news_list": news_items_for_json
            }, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"å­˜æª”å¤±æ•—: {e}")

    status_text.text("âœ… æŠ“å–å®Œæˆï¼è³‡æ–™å·²å­˜å…¥æ­·å²åº«ã€‚")
    time.sleep(1)
    status_text.empty()
    progress_bar.empty()
    
    return output_text

# ================= ç¶²é ä¸»ç¨‹å¼ =================

st.markdown('<div class="big-font">ThaiNews.Ai ğŸ‡¹ğŸ‡­ æˆ°æƒ…å®¤</div>', unsafe_allow_html=True)

tab1, tab2 = st.tabs(["ğŸ¤– ChatGPT æ‡¶äººåŒ… (ç”Ÿæˆå™¨)", "ğŸ“Š æ­·å²æ–°èåº« (å¯æœå°‹)"])

# --- Tab 1 ---
with tab1:
    st.markdown("### ğŸš€ ä¸€éµç”Ÿæˆ ChatGPT åˆ†ææŒ‡ä»¤")
    
    time_options = {
        "1 å¤© (24h)": 1,
        "3 å¤©": 3,
        "1 é€± (7å¤©)": 7,
        "2 é€± (14å¤©)": 14,
        "1 å€‹æœˆ (30å¤©)": 30
    }
    selected_label = st.radio(
        "é¸æ“‡æ–°èå€é–“",
        options=list(time_options.keys()),
        horizontal=True,
        label_visibility="collapsed"
    )
    days_int = time_options[selected_label]

    st.markdown("---")
    col1, col2 = st.columns([3, 1])
    with col1:
        custom_keyword = st.text_input(
            "ğŸ” è‡ªè¨‚æœå°‹é—œéµå­— (é¸å¡«)", 
            placeholder="ä¾‹å¦‚: \"Delta Electronics\" -Airline"
        )
    with col2:
        st.write("") 
        st.caption("âš ï¸ è¼¸å…¥å¾Œå°‡åªæœå°‹æ­¤é—œéµå­—ã€‚")

    st.markdown("---")
    
    if custom_keyword:
        if st.button(f"ğŸ” é–‹å§‹æ·±åº¦æœå°‹: {custom_keyword}", type="primary"):
            with st.spinner(f"æ­£åœ¨å…¨ç¶²æœç´¢..."):
                prompt_content = generate_chatgpt_prompt(selected_label, days_int, custom_keyword)
                st.success("ğŸ‰ ç”ŸæˆæˆåŠŸï¼è«‹é»æ“Šä¸‹æ–¹å€å¡Šå³ä¸Šè§’è¤‡è£½ã€‚")
                st.code(prompt_content, language="markdown")
    else:
        st.markdown("#### è«‹é¸æ“‡æœå°‹ä¸»é¡Œï¼š")
        
        c1, c2, c3 = st.columns(3)
        
        with c1:
            if st.button("ğŸ‡¹ğŸ‡­ 1. æ”¿ç¶“å±€å‹¢ + å°æ³°é—œä¿‚", type="primary"):
                 with st.spinner("æ­£åœ¨æƒææ³°åœ‹å¤§é¸ã€ç¶“è²¿èˆ‡å°æ³°æ–°è..."):
                    prompt_content = generate_chatgpt_prompt(selected_label, days_int, None, category_mode='general')
                    st.success("æ”¿ç¶“æƒ…å‹¢å ±å‘ŠæŒ‡ä»¤ç”Ÿæˆå®Œç•¢ï¼")
                    st.code(prompt_content, language="markdown")
        
        with c2:
            if st.button("ğŸ”Œ 2. PCB èˆ‡é›»å­è£½é€ ", type="secondary"):
                with st.spinner("æ­£åœ¨æƒæ PCB èˆ‡é›»å­ä¾›æ‡‰éˆæ–°è..."):
                    prompt_content = generate_chatgpt_prompt(selected_label, days_int, None, category_mode='pcb')
                    st.success("é›»å­ç”¢æ¥­å ±å‘ŠæŒ‡ä»¤ç”Ÿæˆå®Œç•¢ï¼")
                    st.code(prompt_content, language="markdown")
                    
        with c3:
            if st.button("ğŸ¢ 3. é‡é»å°å•†å‹•æ…‹", type="secondary"):
                with st.spinner("æ­£åœ¨æƒæ 10 å¤§é‡é»å°å•†æ–°è..."):
                    prompt_content = generate_chatgpt_prompt(selected_label, days_int, None, category_mode='vip')
                    st.success("å°å•†ç›£æ¸¬å ±å‘ŠæŒ‡ä»¤ç”Ÿæˆå®Œç•¢ï¼")
                    st.code(prompt_content, language="markdown")

# --- Tab 2 (å¤§æ”¹ç‰ˆï¼šæ–°å¢æœå°‹èˆ‡å¡ç‰‡) ---
with tab2:
    st.markdown("### ğŸ“‚ æœ¬åœ°è³‡æ–™åº«æª¢è¦–")
    
    if os.path.exists('news_data.json'):
        with open('news_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        last_update = data.get('timestamp', 'æœªçŸ¥')
        news_list = data.get('news_list', [])
        
        # 1. é ‚éƒ¨è³‡è¨Šåˆ—
        col_a, col_b = st.columns([3, 1])
        with col_a:
            st.info(f"ğŸ“… ä¸Šæ¬¡æ›´æ–°æ™‚é–“: **{last_update}** (å…± {len(news_list)} å‰‡)")
        with col_b:
            if st.button("ğŸ”„ é‡æ–°è¼‰å…¥"):
                st.rerun()

        # 2. ğŸ” æœå°‹ç¯©é¸å™¨ (é—œéµæ–°åŠŸèƒ½)
        search_query = st.text_input("ğŸ” åœ¨æ­·å²ç´€éŒ„ä¸­æœå°‹...", placeholder="è¼¸å…¥é—œéµå­— (ä¾‹å¦‚: PCB, EV, Investment)")

        # 3. ç¯©é¸é‚è¼¯
        if search_query:
            # åªé¡¯ç¤ºæ¨™é¡ŒåŒ…å«é—œéµå­—çš„æ–°è
            filtered_list = [n for n in news_list if search_query.lower() in n['title'].lower()]
            st.caption(f"æ‰¾åˆ° {len(filtered_list)} å‰‡é—œæ–¼ã€Œ{search_query}ã€çš„æ–°èï¼š")
        else:
            filtered_list = news_list

        # 4. å¡ç‰‡é¡¯ç¤º (ç¾åŒ–ç‰ˆ + é˜²å‘†)
        if len(filtered_list) > 0:
            for news in filtered_list:
                # [ä¿®æ­£] ä½¿ç”¨ .get() é˜²æ­¢èˆŠè³‡æ–™å ±éŒ¯
                category_label = news.get('category', 'æ­·å²æ–°è')
                
                st.markdown(f"""
                <div class="news-card">
                    <a href="{news['link']}" target="_blank" class="news-title">{news['title']}</a>
                    <div class="news-meta">
                        {news['date']} â€¢ {news['source']}
                        <span class="news-tag">{category_label}</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.warning("âš ï¸ æ‰¾ä¸åˆ°ç¬¦åˆæœå°‹æ¢ä»¶çš„æ–°èã€‚")

    else:
        st.warning("ğŸ“­ ç›®å‰æ²’æœ‰æ­·å²ç´€éŒ„ï¼Œè«‹å…ˆåœ¨ã€ç”Ÿæˆå™¨ã€‘åˆ†é åŸ·è¡Œæœå°‹ã€‚")
