import streamlit as st
import feedparser
import time
from datetime import datetime
import json
import os

# ================= 1. é é¢è¨­å®š (å¿…é ˆæ”¾ç¬¬ä¸€è¡Œ) =================
st.set_page_config(
    page_title="ThaiNews.Ai | æˆ°æƒ…å®¤", 
    page_icon="ğŸ‡¹ğŸ‡­", 
    layout="wide"
)

# ================= 2. å¸¸æ•¸èˆ‡ CSS è¨­å®š =================

# CSS ç¾åŒ–æ¨£å¼
CUSTOM_CSS = """
<style>
    .big-font { font-size: 28px !important; font-weight: 800; color: #1a1a1a; margin-bottom: 20px !important; }
    
    /* ç·Šæ¹ŠåŒ–èª¿æ•´ */
    div[data-testid="stVerticalBlock"] > div {
        gap: 0.5rem !important;
    }
    
    .news-card {
        background-color: white;
        padding: 12px;
        border-radius: 8px;
        border: 1px solid #e0e0e0;
        margin-bottom: 8px;
        border-left: 4px solid #d93025;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .news-title {
        font-size: 16px;
        font-weight: 700;
        color: #1a1a1a;
        text-decoration: none;
        display: block;
        margin-bottom: 4px;
    }
    .news-meta { font-size: 13px; color: #666; }
    .news-tag {
        background-color: #f0f0f0;
        padding: 2px 6px;
        border-radius: 4px;
        font-size: 11px;
        margin-left: 8px;
        color: #555;
    }
    
    /* éš±è—é è¨­é€£çµç¬¦è™Ÿ */
    .stMarkdown h1 a, .stMarkdown h2 a, .stMarkdown h3 a, .stMarkdown h4 a, .stMarkdown h5 a {
        display: none !important;
    }
    
    /* æ‰‹æ©Ÿç‰ˆé©é… */
    @media (max-width: 768px) {
        .mobile-hidden { display: none !important; }
        .block-container { padding-top: 2rem !important; }
    }
</style>
"""

# VIP å…¬å¸æ¸…å–®
VIP_COMPANIES_EN = [
    '"Delta Electronics"', '"Zhen Ding"', '"Unimicron"', '"Compeq"', 
    '"Gold Circuit Electronics"', '"Dynamic Holding"', '"Tripod Technology"', 
    '"Unitech"', '"Foxconn"', '"Inventec"'
]

VIP_COMPANIES_CN = [
    '"å°é”é›»"', '"è‡»é¼"', '"æ¬£èˆˆ"', '"è¯é€š"', 
    '"é‡‘åƒé›»"', '"å®šç©"', '"å¥é¼"', 
    '"ç‡¿è¯"', '"é´»æµ·"', '"è‹±æ¥­é”"'
]

# é å…ˆè¨ˆç®—å¥½æŸ¥è©¢å­—ä¸² (é¿å…åœ¨å‡½å¼å…§é‡è¤‡è¨ˆç®—)
VIP_QUERY_EN = "+OR+".join([c.replace(" ", "+") for c in VIP_COMPANIES_EN])
VIP_QUERY_CN = "+OR+".join([c.replace(" ", "+") for c in VIP_COMPANIES_CN])

# é¸é …æ˜ å°„
DATE_MAP = {
    "1å¤©": 1, "3å¤©": 3, "1é€±": 7, "2é€±": 14,
    "1æœˆ": 30, "3æœˆ": 90, "6æœˆ": 180
}

TOPIC_MAP = {
    "æ³°åœ‹æ”¿ç¶“": "macro",
    "é›»å­ç”¢æ¥­": "industry",
    "é‡é»å°å•†": "vip"
}

# å¥—ç”¨ CSS
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# ================= 3. çˆ¬èŸ²æ ¸å¿ƒé‚è¼¯ =================

def get_rss_sources(days, mode="all", custom_keyword=None):
    """
    ç”¢ç”Ÿ RSS ä¾†æºåˆ—è¡¨
    :param days: å¤©æ•¸ (int) -> é€™è£¡å°±æ˜¯ traceback å ±éŒ¯çš„åœ°æ–¹ï¼Œå¿…é ˆç¢ºä¿åƒæ•¸åç‚º days
    """
    sources = []
    
    # è‡ªè¨‚æœå°‹æ¨¡å¼
    if mode == "custom" and custom_keyword:
        clean_keyword = custom_keyword.strip().replace(" ", "+")
        sources.append({
            "name": f"ğŸ” æ·±åº¦è¿½è¹¤: {custom_keyword} (ä¸­)",
            "url": f"https://news.google.com/rss/search?q={clean_keyword}+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
        })
        sources.append({
            "name": f"ğŸ” æ·±åº¦è¿½è¹¤: {custom_keyword} (EN)",
            "url": f"https://news.google.com/rss/search?q={clean_keyword}+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"
        })
        return sources

    # é è¨­æ¨¡å¼
    if mode == "macro":
        sources.extend([
            {"name": "ğŸ‡¹ğŸ‡­ æ³°åœ‹æ•´é«” (ä¸­)", "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"},
            {"name": "ğŸ‡¹ğŸ‡­ æ³°åœ‹æ•´é«” (EN)", "url": f"https://news.google.com/rss/search?q=Thailand+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"},
            {"name": "ğŸ‡¹ğŸ‡¼ å°æ³°é—œä¿‚ (ä¸­)", "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+å°ç£+OR+%22å°å•†%22+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"},
            {"name": "ğŸ‡¹ğŸ‡¼ å°æ³°é—œä¿‚ (EN)", "url": f"https://news.google.com/rss/search?q=Thailand+Taiwan+OR+%22Taiwanese+investment%22+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"}
        ])
    elif mode == "industry":
        sources.extend([
            {"name": "ğŸ”Œ PCBè£½é€  (ä¸­)", "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+PCB+OR+%22é›»å­è£½é€ %22+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"},
            {"name": "ğŸ”Œ PCBè£½é€  (EN)", "url": f"https://news.google.com/rss/search?q=Thailand+PCB+OR+%22Electronics+Manufacturing%22+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"}
        ])
    elif mode == "vip":
        # ä½¿ç”¨å…¨åŸŸè®Šæ•¸ VIP_QUERY_CN/EN
        sources.extend([
            {"name": "ğŸ¢ å°å•†å‹•æ…‹ (ä¸­)", "url": f"https://news.google.com/rss/search?q=æ³°åœ‹+OR+{VIP_QUERY_CN}+when:{days}d&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"},
            {"name": "ğŸ¢ å°å•†å‹•æ…‹ (EN)", "url": f"https://news.google.com/rss/search?q=Thailand+PCB+OR+{VIP_QUERY_EN}+when:{days}d&hl=en-TH&gl=TH&ceid=TH:en"}
        ])
    
    return sources

def generate_chatgpt_prompt(days_label, days_int, search_mode, custom_keyword=None):
    status_text = st.empty() 
    progress_bar = st.progress(0)
    
    # å‘¼å« get_rss_sourcesï¼Œä¸¦å‚³å…¥ days_int ä½œç‚º days åƒæ•¸
    sources = get_rss_sources(days_int, search_mode, custom_keyword)
    news_items_for_json = []

    if search_mode == "custom":
        instruction_prompt = f"é‡å°é—œéµå­—ã€{custom_keyword}ã€‘ï¼Œè«‹æ’°å¯«ä¸€ä»½æ·±åº¦åˆ†æå ±å‘Šï¼š1. é‡é»æ‘˜è¦ 2. å¸‚å ´å½±éŸ¿ 3. æ©Ÿæœƒèˆ‡é¢¨éšªã€‚"
    elif search_mode == "macro":
        instruction_prompt = f"è«‹åˆ†æã€{days_label} æ³°åœ‹æ•´é«”èˆ‡å°æ³°é—œä¿‚ã€‘ï¼š1. æ³°åœ‹æ”¿ç¶“å±€å‹¢ 2. å°æ³°é›™é‚Šäº’å‹•ã€‚"
    elif search_mode == "industry":
        instruction_prompt = f"è«‹åˆ†æã€{days_label} æ³°åœ‹ PCB èˆ‡é›»å­è£½é€ ã€‘ï¼š1. ç”¢æ¥­è¶¨å‹¢ 2. ä¾›æ‡‰éˆå‹•æ…‹ã€‚"
    elif search_mode == "vip":
        instruction_prompt = f"è«‹åˆ†æã€{days_label} æ³°åœ‹é‡é»å°å•†ã€‘ï¼š1. å€‹è‚¡å‹•æ…‹ 2. æŠ•è³‡è¨Šè™Ÿã€‚"

    output_text = f"""
è«‹æ‰®æ¼”ä¸€ä½è³‡æ·±çš„ã€Œç”¢æ¥­åˆ†æå¸«ã€ã€‚
{instruction_prompt}
è«‹ç”¨**ç¹é«”ä¸­æ–‡**ï¼Œä¸¦ä»¥ **Markdown** æ¢åˆ—å¼è¼¸å‡ºï¼Œé¢¨æ ¼éœ€å°ˆæ¥­ä¸”æ˜“è®€ã€‚

========= ä»¥ä¸‹æ˜¯æ–°èè³‡æ–™åº« ({datetime.now().strftime('%Y-%m-%d')}) =========
"""
    
    seen_titles = set()
    total_steps = len(sources)
    
    for i, source in enumerate(sources):
        status_text.text(f"ğŸ“¡ æƒæ: {source['name']} ...")
        
        try:
            feed = feedparser.parse(source['url'])
            if len(feed.entries) > 0:
                output_text += f"\n## ã€{source['name']}ã€‘\n"
                
                # è‡ªè¨‚æœå°‹ä¸è¨­é™ï¼Œé è¨­é™åˆ¶ 30 ç¯‡
                limit = len(feed.entries) if search_mode == "custom" else 30
                
                for entry in feed.entries[:limit]: 
                    if entry.title in seen_titles: continue
                    seen_titles.add(entry.title)
                    source_name = entry.source.title if 'source' in entry else "Google News"
                    pub_date = entry.published if 'published' in entry else ""
                    output_text += f"- [{pub_date}] [{source_name}] {entry.title}\n  é€£çµ: {entry.link}\n"
                    news_items_for_json.append({
                        "title": entry.title, "link": entry.link, "date": pub_date,
                        "source": source_name, "category": source['name']
                    })
            else:
                output_text += f"\n## ã€{source['name']}ã€‘\n(ç„¡ç›¸é—œæ–°è)\n"
        except Exception as e:
            st.error(f"éŒ¯èª¤: {e}")
        
        progress_bar.progress((i + 1) / total_steps)
        time.sleep(0.3)

    output_text += "\n========= è³‡æ–™çµæŸ ========="
    
    try:
        with open('news_data.json', 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "news_list": news_items_for_json
            }, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"å­˜æª”å¤±æ•—: {e}")

    status_text.text("âœ… å®Œæˆï¼")
    time.sleep(0.5)
    status_text.empty()
    progress_bar.empty()
    
    return output_text, news_items_for_json

def display_results(prompt, news_list):
    """é¡¯ç¤ºæœå°‹çµæœçš„å…±ç”¨å‡½æ•¸"""
    st.markdown("##### 1. AI åˆ†ææŒ‡ä»¤")
    with st.expander("é»æ“Šå±•é–‹æŸ¥çœ‹ Prompt", expanded=False):
        st.code(prompt, language="markdown")
        
    st.markdown("##### 2. ç›¸é—œæ–°èé€Ÿè¦½")
    if news_list:
        for news in news_list:
            cat = news.get('category', 'ä¸€èˆ¬')
            st.markdown(f'''
            <div class="news-card">
                <a href="{news['link']}" target="_blank" class="news-title">{news['title']}</a>
                <div class="news-meta">{news['date']} â€¢ {news['source']} <span class="news-tag">{cat}</span></div>
            </div>
            ''', unsafe_allow_html=True)
    else:
        st.warning("æŸ¥ç„¡æ–°èè³‡æ–™ã€‚")

# ================= 4. ç¶²é ä¸»ç¨‹å¼ =================

st.markdown('<div class="big-font">ThaiNews.Ai ğŸ‡¹ğŸ‡­ æˆ°æƒ…å®¤</div>', unsafe_allow_html=True)

tab1, tab2 = st.tabs(["ğŸ¤– ç”Ÿæˆå™¨", "ğŸ“Š æ­·å²åº«"])

with tab1:
    # æ ¸å¿ƒç‰ˆé¢ï¼šå·¦æ§å³é¡¯
    c_left, c_right = st.columns([1, 3], gap="medium")
    
    with c_left:
        st.markdown('<h5 class="mobile-hidden">âš™ï¸ è¨­å®šæ“ä½œ</h5>', unsafe_allow_html=True)
        
        # [ç‹€æ…‹ç®¡ç†]
        if 'days_int' not in st.session_state: st.session_state['days_int'] = 1 
        if 'search_type' not in st.session_state: st.session_state['search_type'] = None
        if 'search_keyword' not in st.session_state: st.session_state['search_keyword'] = ""
        if 'last_topic' not in st.session_state: st.session_state['last_topic'] = None
        
        # [Helper] è¨­å®šæœå°‹æ¨¡å¼
        def set_search(mode, keyword=""):
            st.session_state['search_type'] = mode
            st.session_state['search_keyword'] = keyword

        # 1. æ™‚é–“é¸æ“‡
        st.caption("1. æ™‚é–“ç¯„åœ")
        # æ³¨æ„: st.pills éœ€è¦ Streamlit 1.40.0+
        try:
            date_selection = st.pills("Time", list(DATE_MAP.keys()), default="1å¤©", label_visibility="collapsed", key="pills_date")
        except AttributeError:
            st.error("è«‹æ›´æ–° Streamlit ç‰ˆæœ¬è‡³ 1.40+ ä»¥ä½¿ç”¨ Pills å…ƒä»¶ï¼Œæˆ–æ”¹ç”¨ Radioã€‚")
            date_selection = st.radio("Time", list(DATE_MAP.keys()), horizontal=True, label_visibility="collapsed")
            
        if date_selection:
            st.session_state['days_int'] = DATE_MAP[date_selection] 

        # 2. ä¸»é¡Œé¸æ“‡
        st.caption("2. åˆ†æä¸»é¡Œ")
        try:
            topic_selection = st.pills("Topic", list(TOPIC_MAP.keys()), label_visibility="collapsed", selection_mode="single", key="pills_topic")
        except AttributeError:
            topic_selection = st.radio("Topic", ["(è«‹é¸æ“‡)"] + list(TOPIC_MAP.keys()), label_visibility="collapsed")
            if topic_selection == "(è«‹é¸æ“‡)": topic_selection = None
        
        if topic_selection:
            target_mode = TOPIC_MAP[topic_selection]
            if st.session_state.get('last_topic') != topic_selection:
                st.session_state['last_topic'] = topic_selection 
                set_search(target_mode)
                st.rerun() 
        
        # 3. è‡ªè¨‚æœå°‹
        st.caption("3. é—œéµå­—")
        def handle_custom_search():
            kw = st.session_state.kw_input
            if kw:
                # æ¸…é™¤ä¸»é¡Œé¸å– (å¦‚æœä½¿ç”¨ pills)
                try:
                    st.session_state['pills_topic'] = None 
                except:
                    pass
                st.session_state['last_topic'] = None
                set_search("custom", kw)

        c_in, c_btn = st.columns([3, 1], gap="small")
        with c_in:
            st.text_input("Keywords", placeholder="è¼¸å…¥é—œéµå­—", key="kw_input", on_change=handle_custom_search, label_visibility="collapsed")
        with c_btn:
            st.button("ğŸ”", type="primary", use_container_width=True, on_click=handle_custom_search)

    # å³å´ï¼šé¡¯ç¤ºçµæœå€åŸŸ
    with c_right:
        days_int = st.session_state['days_int']
        selected_label = next((k for k, v in DATE_MAP.items() if v == days_int), f"{days_int}å¤©")
        
        s_type = st.session_state.get('search_type')
        s_kw = st.session_state.get('search_keyword')

        # å°šæœªæœå°‹æ™‚çš„æ­¡è¿ç•«é¢
        if not s_type:
            st.info("ğŸ‘ˆ è«‹å¾å·¦å´é¸æ“‡ä¸»é¡Œæˆ–è¼¸å…¥é—œéµå­—é–‹å§‹ã€‚")
            st.markdown("""
            <div style="background:#f8f9fa; padding:15px; border-radius:10px; color:#555;">
                <strong>ğŸ’¡ ç³»çµ±èªªæ˜ï¼š</strong><br>
                1. <b>æ³°åœ‹æ”¿ç¶“</b>ï¼šæ”¿ç¶“å±€å‹¢èˆ‡å°æ³°é—œä¿‚ã€‚<br>
                2. <b>é›»å­ç”¢æ¥­</b>ï¼šPCBã€ä¼ºæœå™¨èˆ‡é›»å­è£½é€ ã€‚<br>
                3. <b>é‡é»å°å•†</b>ï¼šé–å®š 10 å¤§æŒ‡æ¨™å°å» å‹•æ…‹ã€‚
            </div>
            """, unsafe_allow_html=True)
        
        # åŸ·è¡Œæœå°‹
        else:
            if s_type == "custom" and s_kw:
                with st.spinner(f"æ­£åœ¨å…¨ç¶²æœç´¢ {s_kw}..."):
                    prompt, news_list = generate_chatgpt_prompt(selected_label, days_int, "custom", s_kw)
                    display_results(prompt, news_list)
                    
            elif s_type == "macro":
                with st.spinner("æ­£åœ¨æƒææ³°åœ‹å¤§é¸ã€ç¶“è²¿èˆ‡å°æ³°æ–°è..."):
                    prompt, news_list = generate_chatgpt_prompt(selected_label, days_int, "macro")
                    display_results(prompt, news_list)
                    
            elif s_type == "industry":
                with st.spinner("æ­£åœ¨æƒæ PCB èˆ‡é›»å­ä¾›æ‡‰éˆæ–°è..."):
                    prompt, news_list = generate_chatgpt_prompt(selected_label, days_int, "industry")
                    display_results(prompt, news_list)
                    
            elif s_type == "vip":
                with st.spinner("æ­£åœ¨æƒæé‡é»å°å•†å‹•æ…‹..."):
                    prompt, news_list = generate_chatgpt_prompt(selected_label, days_int, "vip")
                    display_results(prompt, news_list)

with tab2:
    col_head_1, col_head_2 = st.columns([3, 1])
    with col_head_1:
        st.markdown("### ğŸ“‚ æ­·å²æ–°èè³‡æ–™åº«")
    with col_head_2:
        if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨"): st.rerun()
    
    if os.path.exists('news_data.json'):
        with open('news_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        news_list = data.get('news_list', [])
        st.caption(f"ğŸ“… ä¸Šæ¬¡æ›´æ–°: {data.get('timestamp', 'æœªçŸ¥')} (å…± {len(news_list)} å‰‡)")

        search_query = st.text_input("ğŸ” æœå°‹æ­·å²...", placeholder="è«‹è¼¸å…¥æ¨™é¡Œé—œéµå­—")
        if search_query:
            news_list = [n for n in news_list if search_query.lower() in n['title'].lower()]

        if news_list:
            for news in news_list:
                cat = news.get('category', 'æ­·å²')
                st.markdown(f"""
                <div class="news-card">
                    <a href="{news['link']}" target="_blank" class="news-title">{news['title']}</a>
                    <div class="news-meta">{news['date']} â€¢ {news['source']} <span class="news-tag">{cat}</span></div>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.warning("ç„¡ç¬¦åˆè³‡æ–™")
    else:
        st.info("å°šç„¡æ­·å²ç´€éŒ„ï¼Œè«‹å…ˆåœ¨ç”Ÿæˆå™¨åŸ·è¡Œæœå°‹ã€‚")