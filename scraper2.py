import feedparser
import time
from datetime import datetime, timedelta

# =================è¨­å®šå€=================
# è¨­å®šæœå°‹ç¯„åœï¼šéå» 14 å¤© (when:14d)
# é‡å°ä¸‰å¤§æˆ°ç•¥æ–¹å‘è¨­å®šç²¾æº–é—œéµå­—
RSS_SOURCES = [
    {
        "name": "ğŸ‡¹ğŸ‡­ 1. æ³°åœ‹æ•´é«”é‡è¦æ–°è (General News)", 
        # æœå°‹æ³°åœ‹æ•´é«”å¤§æ–°èï¼Œæ’é™¤éæ–¼ç‘£ç¢çš„å…§å®¹
        "url": "https://news.google.com/rss/search?q=Thailand+when:14d&hl=en-TH&gl=TH&ceid=TH:en"
    },
    {
        "name": "ğŸ”Œ 2. PCB èˆ‡é›»å­è£½é€  (PCB & Electronics)", 
        # é–å®š PCBã€é›»è·¯æ¿ã€é›»å­è£½é€ ã€ä¼ºæœå™¨ä¾›æ‡‰éˆ
        "url": "https://news.google.com/rss/search?q=Thailand+PCB+OR+%22Printed+Circuit+Board%22+OR+%22Electronics+Manufacturing%22+OR+%22Server+Production%22+when:14d&hl=en-TH&gl=TH&ceid=TH:en"
    },
    {
        "name": "ğŸ‡¹ğŸ‡¼ 3. å°æ³°é—œä¿‚ (Taiwan-Thailand Relations)", 
        # é–å®šå°ç£æŠ•è³‡ã€å°å•†ã€é›™é‚Šé—œä¿‚
        "url": "https://news.google.com/rss/search?q=Thailand+Taiwan+OR+%22Taiwanese+investment%22+OR+%22Taiwan+companies%22+OR+%22Trade+Relations%22+when:14d&hl=en-TH&gl=TH&ceid=TH:en"
    }
]
# =======================================

def get_thai_news():
    print(f"ğŸš€ å•Ÿå‹•å…©é€±æˆ°æƒ…æŠ“å–å™¨ ({datetime.now().strftime('%Y-%m-%d')})...")
    
    # è‡ªå‹•ç”Ÿæˆçµ¦ ChatGPT çš„ Prompt
    output_text = f"""
è«‹æ‰®æ¼”ä¸€ä½è³‡æ·±çš„ã€Œæ±å—äºç”¢ç¶“åˆ†æå¸«ã€ã€‚
ä»¥ä¸‹æ˜¯æˆ‘é€éç¨‹å¼æŠ“å–çš„ã€éå» 14 å¤© (è¿‘å…©é€±) æ³°åœ‹æ–°èè³‡æ–™åº«ã€‘ã€‚

è«‹é–±è®€é€™äº›æ–°èæ¨™é¡Œèˆ‡ä¾†æºï¼Œå¹«æˆ‘æŒ‰ç…§ä»¥ä¸‹ä¸‰å€‹æ–¹å‘é€²è¡Œã€Œæ·±åº¦æ•´ç†èˆ‡åˆ†æã€ï¼š

### 1. ğŸ‡¹ğŸ‡­ æ³°åœ‹æ•´é«”é‡è¦æ–°è
   - é‡é»é—œæ³¨ï¼šæ”¿æ²»å‹•æ…‹ï¼ˆå¦‚é¸èˆ‰ã€å…§é–£ï¼‰ã€é‡å¤§ç¶“æ¿Ÿæ”¿ç­–ã€ç¤¾æœƒå®‰å…¨ï¼ˆå¦‚é‚Šå¢ƒè¡çªã€å—éƒ¨å‹•äº‚ï¼‰ã€‚
   - è«‹åˆ—å‡ºæœ€å…·å½±éŸ¿åŠ›çš„ 3-5 ä»¶å¤§äº‹ã€‚

### 2. ğŸ”Œ æ³°åœ‹ PCB èˆ‡é›»å­è£½é€ 
   - é‡é»é—œæ³¨ï¼šæ–°å» è¨­ç«‹ï¼ˆç‰¹åˆ¥æ˜¯ PCB å» ï¼‰ã€ä¾›æ‡‰éˆç§»è½‰å‹•æ…‹ã€å¤§å‹æŠ•è³‡æ¡ˆï¼ˆå¦‚ AWS, Google æˆ–å°å» ï¼‰ã€‚
   - è«‹åˆ†æé€™å°å…¨çƒé›»å­ä¾›æ‡‰éˆçš„æ„ç¾©ã€‚

### 3. ğŸ‡¹ğŸ‡¼ å°æ³°é—œä¿‚èˆ‡å°å•†å‹•æ…‹
   - é‡é»é—œæ³¨ï¼šå°ç£ä¼æ¥­åœ¨æ³°æŠ•è³‡æ–°è¨Šã€é›™é‚Šè²¿æ˜“å”å®šã€äººæ‰äº¤æµæˆ–åœ°ç·£æ”¿æ²»å½±éŸ¿ã€‚
   - è«‹æŒ‡å‡ºå°å•†åœ¨æ³°åœ‹çš„æ©Ÿæœƒæˆ–æ½›åœ¨é¢¨éšªã€‚

è«‹ç”¨**ç¹é«”ä¸­æ–‡**ï¼Œä¸¦ä»¥ **Markdown** æ¢åˆ—å¼è¼¸å‡ºï¼Œé¢¨æ ¼éœ€å°ˆæ¥­ä¸”æ˜“è®€ã€‚

========= ä»¥ä¸‹æ˜¯è¿‘å…©é€±æ–°èè³‡æ–™åº« =========
"""

    total_count = 0
    seen_titles = set()

    for source in RSS_SOURCES:
        print(f"ğŸ“¡ æ­£åœ¨æƒæ: {source['name']} ...")
        feed = feedparser.parse(source['url'])
        
        if len(feed.entries) > 0:
            output_text += f"\n## ã€{source['name']}ã€‘\n"
            
            count = 0
            # å…©é€±çš„æ–°èé‡è¼ƒå¤§ï¼Œæˆ‘å€‘æ¯å€‹åˆ†é¡æŠ“å‰ 20-30 å‰‡æ¯”è¼ƒå‰›å¥½ï¼Œé¿å… ChatGPT åƒä¸æ¶ˆ
            for entry in feed.entries[:30]: 
                if entry.title in seen_titles:
                    continue
                seen_titles.add(entry.title)
                
                clean_title = entry.title
                source_name = entry.source.title if 'source' in entry else "Unknown"
                pub_date = entry.published if 'published' in entry else "Unknown Date"
                
                output_text += f"- [{pub_date}] [{source_name}] {clean_title}\n  é€£çµ: {entry.link}\n"
                count += 1
            
            output_text += "\n"
            total_count += count
            print(f"   âœ… æŠ“å– {count} å‰‡")
        else:
            print("   âš ï¸ ç„¡è³‡æ–™")
        
        time.sleep(1) # ä¼‘æ¯ä¸€ä¸‹é¿å…è¢«æ“‹

    output_text += "\n========= è³‡æ–™çµæŸ ========="

    filename = "chatgpt_prompt_2weeks.txt"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(output_text)

    print("-" * 30)
    print(f"ğŸ‰ æˆåŠŸï¼å…±æ•´ç†äº† {total_count} å‰‡è¿‘å…©é€±æ–°èã€‚")
    print(f"ğŸ“„ è«‹æ‰“é–‹å·¦å´æª”æ¡ˆã€{filename}ã€‘ï¼Œå…¨é¸è¤‡è£½ä¸¦è²¼çµ¦ ChatGPTï¼")

if __name__ == "__main__":
    get_thai_news()